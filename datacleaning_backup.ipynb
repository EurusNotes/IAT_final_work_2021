{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "90e28582119bce0cc274c6d6dfe19355fcd1274cf7010646f013c0dc14b616bf"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "paper = [\n",
    "         'Combining Character and Word Information in Neural Machine Translation Using a Multi-Level Attention',\n",
    "         'On the value of temporal information in information retrieval',\n",
    "         'Learning Curve Prediction with Bayesian Neural Networks',\n",
    "         'Leveraging linguistic structure for open domain information extraction',\n",
    "         'Speeding up the hyperparameter optimization of deep convolutional neural net-works',\n",
    "         'Resource leveling in construction projects with activity splitting and resource constraints: a simulated annealing optimization',\n",
    "         'Temporal Information Retrieval: Challenges and Opportunities.',\n",
    "         'Hyperparameter Optimization: A Spectral Approach',\n",
    "         'Bayesian optimization with robust Bayesian neural networks',\n",
    "         'Variational learning of inducing variables in sparse Gaussian processes',\n",
    "         'Temporal information in speech: acoustic, auditory and linguistic aspects',\n",
    "         'Google’s neural machine translation system: Bridging the gap between human and machine translation',\n",
    "         'Optuna: A Next-generation Hyperparameter Optimization Framework',\n",
    "         'Information retrieval as statistical translation',\n",
    "         'Speeding up Hyper-parameter Optimization by Extrapolation of Learning Curves Using Previous Builds',\n",
    "         'Optimal hyperparameters for deep lstm-networks for sequence labeling tasks',\n",
    "         'Enriching word vectors with subword information',\n",
    "         'Speeding up automatic hyperparameter optimization of deep neural networks by extrapolation of learning curves',\n",
    "         'Neural machine translation in linear time',\n",
    "         'A System for Massively Parallel Hyperparameter Tuning',\n",
    "         'Linguistic input features improve neural machine translation',\n",
    "         'Predictive entropy search for efficient global optimization of black-box functions',\n",
    "         'Semeval-2015 task 5: Qa tempeval-evaluating temporal information under-standing with question answering',\n",
    "         'Lmu munich’s neural machine translation systems for news articles and health information texts',\n",
    "         'Accelerating neural architecture search using performance prediction',\n",
    "         'Recent approaches to global optimization problems through particle swarm optimization',\n",
    "         'Reactive Search and Intelligent Optimization',\n",
    "         'Space mapping technique for electromagnetic optimization',\n",
    "         'Nonlinear multiobjective optimization',\n",
    "         'Hyperband: A novel bandit-based approach to hyperparameter optimization'\n",
    "\n",
    "]"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['combining character and word information in neural machine translation using a multilevel attention',\n",
       " 'on the value of temporal information in information retrieval',\n",
       " 'learning curve prediction with bayesian neural networks',\n",
       " 'leveraging linguistic structure for open domain information extraction',\n",
       " 'speeding up the hyperparameter optimization of deep convolutional neural networks',\n",
       " 'resource leveling in construction projects with activity splitting and resource constraints a simulated annealing optimization',\n",
       " 'temporal information retrieval challenges and opportunities',\n",
       " 'hyperparameter optimization a spectral approach',\n",
       " 'bayesian optimization with robust bayesian neural networks',\n",
       " 'variational learning of inducing variables in sparse gaussian processes',\n",
       " 'temporal information in speech acoustic, auditory and linguistic aspects',\n",
       " 'google neural machine translation system bridging the gap between human and machine translation',\n",
       " 'optuna a nextgeneration hyperparameter optimization framework',\n",
       " 'information retrieval as statistical translation',\n",
       " 'speeding up hyperparameter optimization by extrapolation of learning curves using previous builds',\n",
       " 'optimal hyperparameters for deep lstmnetworks for sequence labeling tasks',\n",
       " 'enriching word vectors with subword information',\n",
       " 'speeding up automatic hyperparameter optimization of deep neural networks by extrapolation of learning curves',\n",
       " 'neural machine translation in linear time',\n",
       " 'a system for massively parallel hyperparameter tuning',\n",
       " 'linguistic input features improve neural machine translation',\n",
       " 'predictive entropy search for efficient global optimization of blackbox functions',\n",
       " 'semeval2015 task 5 qa tempevalevaluating temporal information understanding with question answering',\n",
       " 'lmu munich neural machine translation systems for news articles and health information texts',\n",
       " 'accelerating neural architecture search using performance prediction',\n",
       " 'recent approaches to global optimization problems through particle swarm optimization',\n",
       " 'reactive search and intelligent optimization',\n",
       " 'space mapping technique for electromagnetic optimization',\n",
       " 'nonlinear multiobjective optimization',\n",
       " 'hyperband a novel banditbased approach to hyperparameter optimization']"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "paper"
   ]
  },
  {
   "source": [
    "# 文字変換"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['combining character and word information in neural machine translation using a multilevel attention',\n",
       " 'on the value of temporal information in information retrieval',\n",
       " 'learning curve prediction with bayesian neural networks',\n",
       " 'leveraging linguistic structure for open domain information extraction',\n",
       " 'speeding up the hyperparameter optimization of deep convolutional neural networks',\n",
       " 'resource leveling in construction projects with activity splitting and resource constraints a simulated annealing optimization',\n",
       " 'temporal information retrieval challenges and opportunities',\n",
       " 'hyperparameter optimization a spectral approach',\n",
       " 'bayesian optimization with robust bayesian neural networks',\n",
       " 'variational learning of inducing variables in sparse gaussian processes',\n",
       " 'temporal information in speech acoustic, auditory and linguistic aspects',\n",
       " 'google neural machine translation system bridging the gap between human and machine translation',\n",
       " 'optuna a nextgeneration hyperparameter optimization framework',\n",
       " 'information retrieval as statistical translation',\n",
       " 'speeding up hyperparameter optimization by extrapolation of learning curves using previous builds',\n",
       " 'optimal hyperparameters for deep lstmnetworks for sequence labeling tasks',\n",
       " 'enriching word vectors with subword information',\n",
       " 'speeding up automatic hyperparameter optimization of deep neural networks by extrapolation of learning curves',\n",
       " 'neural machine translation in linear time',\n",
       " 'a system for massively parallel hyperparameter tuning',\n",
       " 'linguistic input features improve neural machine translation',\n",
       " 'predictive entropy search for efficient global optimization of blackbox functions',\n",
       " 'semeval2015 task 5 qa tempevalevaluating temporal information understanding with question answering',\n",
       " 'lmu munich neural machine translation systems for news articles and health information texts',\n",
       " 'accelerating neural architecture search using performance prediction',\n",
       " 'recent approaches to global optimization problems through particle swarm optimization',\n",
       " 'reactive search and intelligent optimization',\n",
       " 'space mapping technique for electromagnetic optimization',\n",
       " 'nonlinear multiobjective optimization',\n",
       " 'hyperband a novel banditbased approach to hyperparameter optimization']"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "#  小文字に変換\n",
    "\n",
    "for i in range(len(paper)):\n",
    "    paper[i] = paper[i].lower()\n",
    "paper "
   ]
  },
  {
   "source": [
    "# 記号の削除"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['combining character and word information in neural machine translation using a multilevel attention',\n",
       " 'on the value of temporal information in information retrieval',\n",
       " 'learning curve prediction with bayesian neural networks',\n",
       " 'leveraging linguistic structure for open domain information extraction',\n",
       " 'speeding up the hyperparameter optimization of deep convolutional neural networks',\n",
       " 'resource leveling in construction projects with activity splitting and resource constraints a simulated annealing optimization',\n",
       " 'temporal information retrieval challenges and opportunities',\n",
       " 'hyperparameter optimization a spectral approach',\n",
       " 'bayesian optimization with robust bayesian neural networks',\n",
       " 'variational learning of inducing variables in sparse gaussian processes',\n",
       " 'temporal information in speech acoustic, auditory and linguistic aspects',\n",
       " 'google neural machine translation system bridging the gap between human and machine translation',\n",
       " 'optuna a nextgeneration hyperparameter optimization framework',\n",
       " 'information retrieval as statistical translation',\n",
       " 'speeding up hyperparameter optimization by extrapolation of learning curves using previous builds',\n",
       " 'optimal hyperparameters for deep lstmnetworks for sequence labeling tasks',\n",
       " 'enriching word vectors with subword information',\n",
       " 'speeding up automatic hyperparameter optimization of deep neural networks by extrapolation of learning curves',\n",
       " 'neural machine translation in linear time',\n",
       " 'a system for massively parallel hyperparameter tuning',\n",
       " 'linguistic input features improve neural machine translation',\n",
       " 'predictive entropy search for efficient global optimization of blackbox functions',\n",
       " 'semeval2015 task 5 qa tempevalevaluating temporal information understanding with question answering',\n",
       " 'lmu munich neural machine translation systems for news articles and health information texts',\n",
       " 'accelerating neural architecture search using performance prediction',\n",
       " 'recent approaches to global optimization problems through particle swarm optimization',\n",
       " 'reactive search and intelligent optimization',\n",
       " 'space mapping technique for electromagnetic optimization',\n",
       " 'nonlinear multiobjective optimization',\n",
       " 'hyperband a novel banditbased approach to hyperparameter optimization']"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "for i in range(len(paper)):\n",
    "    # -\n",
    "    paper[i] = paper[i].replace('-','')\n",
    "    # .\n",
    "    paper[i] = paper[i].replace('.','')\n",
    "    # :\n",
    "    paper[i] = paper[i].replace(':','')\n",
    "    # '\n",
    "    paper[i] = paper[i].replace(\"’s\",\"\")\n",
    "    # ,\n",
    "    paper[i] = paper[i].replace(\",'\",\"\")\n",
    "\n",
    "paper\n"
   ]
  },
  {
   "source": [
    "# Delete Stopwords"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = pd.read_csv('/Users/chenxiliu/Desktop/Doshisha/2021SS/情報アクセス技術/期末レポート/RAKE-master/FoxStoplist.txt',header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword.columns = ['words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        words\n",
       "0           a\n",
       "1       about\n",
       "2       above\n",
       "3      across\n",
       "4       after\n",
       "..        ...\n",
       "420   younger\n",
       "421  youngest\n",
       "422      your\n",
       "423     yours\n",
       "424         z\n",
       "\n",
       "[425 rows x 1 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>words</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>about</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>above</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>across</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>after</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>420</th>\n      <td>younger</td>\n    </tr>\n    <tr>\n      <th>421</th>\n      <td>youngest</td>\n    </tr>\n    <tr>\n      <th>422</th>\n      <td>your</td>\n    </tr>\n    <tr>\n      <th>423</th>\n      <td>yours</td>\n    </tr>\n    <tr>\n      <th>424</th>\n      <td>z</td>\n    </tr>\n  </tbody>\n</table>\n<p>425 rows × 1 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# delete stopwords function\n",
    "def dele_sw(split_list):\n",
    "    for i in split_list:\n",
    "        for j in stopword['words']:\n",
    "            if i == j:\n",
    "                split_list.remove(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split\n",
    "title_split = []\n",
    "for i in paper:\n",
    "    sp = i.split()\n",
    "    title_split.append(list(sp))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['combining',\n",
       " 'character',\n",
       " 'and',\n",
       " 'word',\n",
       " 'information',\n",
       " 'in',\n",
       " 'neural',\n",
       " 'machine',\n",
       " 'translation',\n",
       " 'using',\n",
       " 'a',\n",
       " 'multilevel',\n",
       " 'attention']"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "title_split[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy\n",
    "dele_sw_list = title_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete stopwords\n",
    "\n",
    "for words in dele_sw_list:\n",
    "    dele_sw(words)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['combining',\n",
       "  'character',\n",
       "  'word',\n",
       "  'information',\n",
       "  'neural',\n",
       "  'machine',\n",
       "  'translation',\n",
       "  'using',\n",
       "  'multilevel',\n",
       "  'attention'],\n",
       " ['the', 'value', 'temporal', 'information', 'information', 'retrieval'],\n",
       " ['learning', 'curve', 'prediction', 'bayesian', 'neural', 'networks'],\n",
       " ['leveraging',\n",
       "  'linguistic',\n",
       "  'structure',\n",
       "  'open',\n",
       "  'domain',\n",
       "  'information',\n",
       "  'extraction'],\n",
       " ['speeding',\n",
       "  'the',\n",
       "  'hyperparameter',\n",
       "  'optimization',\n",
       "  'deep',\n",
       "  'convolutional',\n",
       "  'neural',\n",
       "  'networks'],\n",
       " ['resource',\n",
       "  'leveling',\n",
       "  'construction',\n",
       "  'projects',\n",
       "  'activity',\n",
       "  'splitting',\n",
       "  'resource',\n",
       "  'constraints',\n",
       "  'simulated',\n",
       "  'annealing',\n",
       "  'optimization'],\n",
       " ['temporal', 'information', 'retrieval', 'challenges', 'opportunities'],\n",
       " ['hyperparameter', 'optimization', 'spectral', 'approach'],\n",
       " ['bayesian', 'optimization', 'robust', 'bayesian', 'neural', 'networks'],\n",
       " ['variational',\n",
       "  'learning',\n",
       "  'inducing',\n",
       "  'variables',\n",
       "  'sparse',\n",
       "  'gaussian',\n",
       "  'processes'],\n",
       " ['temporal',\n",
       "  'information',\n",
       "  'speech',\n",
       "  'acoustic,',\n",
       "  'auditory',\n",
       "  'linguistic',\n",
       "  'aspects'],\n",
       " ['google',\n",
       "  'neural',\n",
       "  'machine',\n",
       "  'translation',\n",
       "  'system',\n",
       "  'bridging',\n",
       "  'gap',\n",
       "  'human',\n",
       "  'machine',\n",
       "  'translation'],\n",
       " ['optuna', 'nextgeneration', 'hyperparameter', 'optimization', 'framework'],\n",
       " ['information', 'retrieval', 'statistical', 'translation'],\n",
       " ['speeding',\n",
       "  'hyperparameter',\n",
       "  'optimization',\n",
       "  'extrapolation',\n",
       "  'learning',\n",
       "  'curves',\n",
       "  'using',\n",
       "  'previous',\n",
       "  'builds'],\n",
       " ['optimal',\n",
       "  'hyperparameters',\n",
       "  'deep',\n",
       "  'lstmnetworks',\n",
       "  'sequence',\n",
       "  'labeling',\n",
       "  'tasks'],\n",
       " ['enriching', 'word', 'vectors', 'subword', 'information'],\n",
       " ['speeding',\n",
       "  'automatic',\n",
       "  'hyperparameter',\n",
       "  'optimization',\n",
       "  'deep',\n",
       "  'neural',\n",
       "  'networks',\n",
       "  'extrapolation',\n",
       "  'learning',\n",
       "  'curves'],\n",
       " ['neural', 'machine', 'translation', 'linear', 'time'],\n",
       " ['system', 'massively', 'parallel', 'hyperparameter', 'tuning'],\n",
       " ['linguistic',\n",
       "  'input',\n",
       "  'features',\n",
       "  'improve',\n",
       "  'neural',\n",
       "  'machine',\n",
       "  'translation'],\n",
       " ['predictive',\n",
       "  'entropy',\n",
       "  'search',\n",
       "  'efficient',\n",
       "  'global',\n",
       "  'optimization',\n",
       "  'blackbox',\n",
       "  'functions'],\n",
       " ['semeval2015',\n",
       "  'task',\n",
       "  '5',\n",
       "  'qa',\n",
       "  'tempevalevaluating',\n",
       "  'temporal',\n",
       "  'information',\n",
       "  'understanding',\n",
       "  'question',\n",
       "  'answering'],\n",
       " ['lmu',\n",
       "  'munich',\n",
       "  'neural',\n",
       "  'machine',\n",
       "  'translation',\n",
       "  'systems',\n",
       "  'news',\n",
       "  'articles',\n",
       "  'health',\n",
       "  'information',\n",
       "  'texts'],\n",
       " ['accelerating',\n",
       "  'neural',\n",
       "  'architecture',\n",
       "  'search',\n",
       "  'using',\n",
       "  'performance',\n",
       "  'prediction'],\n",
       " ['recent',\n",
       "  'approaches',\n",
       "  'global',\n",
       "  'optimization',\n",
       "  'through',\n",
       "  'particle',\n",
       "  'swarm',\n",
       "  'optimization'],\n",
       " ['reactive', 'search', 'intelligent', 'optimization'],\n",
       " ['space', 'mapping', 'technique', 'electromagnetic', 'optimization'],\n",
       " ['nonlinear', 'multiobjective', 'optimization'],\n",
       " ['hyperband',\n",
       "  'novel',\n",
       "  'banditbased',\n",
       "  'approach',\n",
       "  'hyperparameter',\n",
       "  'optimization']]"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "dele_sw_list"
   ]
  },
  {
   "source": [
    "## finished stopwords"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "paper No.1['combining', 'character', 'word', 'information', 'neural', 'machine', 'translation', 'using', 'multilevel', 'attention']\npaper No.2['the', 'value', 'temporal', 'information', 'information', 'retrieval']\npaper No.3['learning', 'curve', 'prediction', 'bayesian', 'neural', 'networks']\npaper No.4['leveraging', 'linguistic', 'structure', 'open', 'domain', 'information', 'extraction']\npaper No.5['speeding', 'the', 'hyperparameter', 'optimization', 'deep', 'convolutional', 'neural', 'networks']\npaper No.6['resource', 'leveling', 'construction', 'projects', 'activity', 'splitting', 'resource', 'constraints', 'simulated', 'annealing', 'optimization']\npaper No.7['temporal', 'information', 'retrieval', 'challenges', 'opportunities']\npaper No.8['hyperparameter', 'optimization', 'spectral', 'approach']\npaper No.9['bayesian', 'optimization', 'robust', 'bayesian', 'neural', 'networks']\npaper No.10['variational', 'learning', 'inducing', 'variables', 'sparse', 'gaussian', 'processes']\npaper No.11['temporal', 'information', 'speech', 'acoustic,', 'auditory', 'linguistic', 'aspects']\npaper No.12['google', 'neural', 'machine', 'translation', 'system', 'bridging', 'gap', 'human', 'machine', 'translation']\npaper No.13['optuna', 'nextgeneration', 'hyperparameter', 'optimization', 'framework']\npaper No.14['information', 'retrieval', 'statistical', 'translation']\npaper No.15['speeding', 'hyperparameter', 'optimization', 'extrapolation', 'learning', 'curves', 'using', 'previous', 'builds']\npaper No.16['optimal', 'hyperparameters', 'deep', 'lstmnetworks', 'sequence', 'labeling', 'tasks']\npaper No.17['enriching', 'word', 'vectors', 'subword', 'information']\npaper No.18['speeding', 'automatic', 'hyperparameter', 'optimization', 'deep', 'neural', 'networks', 'extrapolation', 'learning', 'curves']\npaper No.19['neural', 'machine', 'translation', 'linear', 'time']\npaper No.20['system', 'massively', 'parallel', 'hyperparameter', 'tuning']\npaper No.21['linguistic', 'input', 'features', 'improve', 'neural', 'machine', 'translation']\npaper No.22['predictive', 'entropy', 'search', 'efficient', 'global', 'optimization', 'blackbox', 'functions']\npaper No.23['semeval2015', 'task', '5', 'qa', 'tempevalevaluating', 'temporal', 'information', 'understanding', 'question', 'answering']\npaper No.24['lmu', 'munich', 'neural', 'machine', 'translation', 'systems', 'news', 'articles', 'health', 'information', 'texts']\npaper No.25['accelerating', 'neural', 'architecture', 'search', 'using', 'performance', 'prediction']\npaper No.26['recent', 'approaches', 'global', 'optimization', 'through', 'particle', 'swarm', 'optimization']\npaper No.27['reactive', 'search', 'intelligent', 'optimization']\npaper No.28['space', 'mapping', 'technique', 'electromagnetic', 'optimization']\npaper No.29['nonlinear', 'multiobjective', 'optimization']\npaper No.30['hyperband', 'novel', 'banditbased', 'approach', 'hyperparameter', 'optimization']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(len(dele_sw_list)):\n",
    "    print('paper No.'+str(i+1)+str(dele_sw_list[i]))"
   ]
  },
  {
   "source": [
    "# 接辞処理"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer as PS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/chenxiliu/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "sentence = \"numpang wifi stop gadget shopping\"\n",
    "tokens = word_tokenize(sentence)\n",
    "stemmer=PorterStemmer()\n",
    "\n",
    "Output=[stemmer.stem(word) for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['numpang', 'wifi', 'stop', 'gadget', 'shop']"
      ]
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem = dele_sw_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dele_sw_list)):\n",
    "    for j in range(len(dele_sw_list[i])):\n",
    "        stem[i][j] = stemmer.stem(dele_sw_list[i][j])"
   ]
  },
  {
   "source": [
    "## finished stem"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "combin charact word inform neural machin translat use multilevel attent\nthe valu tempor inform inform retriev\nlearn curv predict bayesian neural network\nleverag linguist structur open domain inform extract\nspeed the hyperparamet optim deep convolut neural network\nresourc level construct project activ split resourc constraint simul anneal optim\ntempor inform retriev challeng opportun\nhyperparamet optim spectral approach\nbayesian optim robust bayesian neural network\nvariat learn induc variabl spars gaussian process\ntempor inform speech acoustic, auditori linguist aspect\ngoogl neural machin translat system bridg gap human machin translat\noptuna nextgener hyperparamet optim framework\ninform retriev statist translat\nspeed hyperparamet optim extrapol learn curv use previou build\noptim hyperparamet deep lstmnetwork sequenc label task\nenrich word vector subword inform\nspeed automat hyperparamet optim deep neural network extrapol learn curv\nneural machin translat linear time\nsystem massiv parallel hyperparamet tune\nlinguist input featur improv neural machin translat\npredict entropi search effici global optim blackbox function\nsemeval2015 task 5 qa tempevalevalu tempor inform understand question answer\nlmu munich neural machin translat system news articl health inform text\nacceler neural architectur search use perform predict\nrecent approach global optim through particl swarm optim\nreactiv search intellig optim\nspace map techniqu electromagnet optim\nnonlinear multiobject optim\nhyperband novel banditbas approach hyperparamet optim\n"
     ]
    }
   ],
   "source": [
    "for i in stem:\n",
    "    print(*i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Paper 1, combin, charact, word, inform, neural, machin, translat, use, multilevel, attent\nPaper 2, the, valu, tempor, inform, inform, retriev\nPaper 3, learn, curv, predict, bayesian, neural, network\nPaper 4, leverag, linguist, structur, open, domain, inform, extract\nPaper 5, speed, the, hyperparamet, optim, deep, convolut, neural, network\nPaper 6, resourc, level, construct, project, activ, split, resourc, constraint, simul, anneal, optim\nPaper 7, tempor, inform, retriev, challeng, opportun\nPaper 8, hyperparamet, optim, spectral, approach\nPaper 9, bayesian, optim, robust, bayesian, neural, network\nPaper 10, variat, learn, induc, variabl, spars, gaussian, process\nPaper 11, tempor, inform, speech, acoustic,, auditori, linguist, aspect\nPaper 12, googl, neural, machin, translat, system, bridg, gap, human, machin, translat\nPaper 13, optuna, nextgener, hyperparamet, optim, framework\nPaper 14, inform, retriev, statist, translat\nPaper 15, speed, hyperparamet, optim, extrapol, learn, curv, use, previou, build\nPaper 16, optim, hyperparamet, deep, lstmnetwork, sequenc, label, task\nPaper 17, enrich, word, vector, subword, inform\nPaper 18, speed, automat, hyperparamet, optim, deep, neural, network, extrapol, learn, curv\nPaper 19, neural, machin, translat, linear, time\nPaper 20, system, massiv, parallel, hyperparamet, tune\nPaper 21, linguist, input, featur, improv, neural, machin, translat\nPaper 22, predict, entropi, search, effici, global, optim, blackbox, function\nPaper 23, semeval2015, task, 5, qa, tempevalevalu, tempor, inform, understand, question, answer\nPaper 24, lmu, munich, neural, machin, translat, system, news, articl, health, inform, text\nPaper 25, acceler, neural, architectur, search, use, perform, predict\nPaper 26, recent, approach, global, optim, through, particl, swarm, optim\nPaper 27, reactiv, search, intellig, optim\nPaper 28, space, map, techniqu, electromagnet, optim\nPaper 29, nonlinear, multiobject, optim\nPaper 30, hyperband, novel, banditbas, approach, hyperparamet, optim\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(stem)):\n",
    "    print('Paper '+str(i+1), *stem[i],sep=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}